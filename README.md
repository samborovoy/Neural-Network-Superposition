# Neural-Network-Superposition
This repo explores how neural networks represent features in activation space, focusing on MLP blocks in Transformers. It examines superposition, enabling networks to encode more features than neurons, and how input sparsity drives polysemanticity, where neurons encode multiple features, reducing interpretability.


For further information, check out my full paper that is attached in the repo, along with the code that was used to generate some of the results!
